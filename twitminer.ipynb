{
 "metadata": {
  "name": "Untitled5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Naive Bayes Classifier to classify labels into 'Sports' or 'Politics'"
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Libraries"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import re\nimport csv\nimport nltk.classify\nimport time\nimport pickle\nimport os",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Clean : Remove unecessary components "
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def clean(tweet):\n    #lower case\n    tweet = tweet.lower()\n    #@username to username\n    tweet = re.sub('@([^\\s]+)','\\1',tweet)\n    #Remove additional white spaces\n    tweet = re.sub('[\\s]+', ' ', tweet)\n    ##word to word\n    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n    #trim\n    tweet = tweet.strip('\\'\"')\n    return tweet",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Extracts stop words from pre-existing file"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def extractStopWords(FileName):\n    #read the stopwords\n    stopWords = []\n    stopWords.append('AT_USER')\n    stopWords.append('URL')\n\n    fp = open(FileName, 'r')\n    line = fp.readline()\n    while line:\n        word = line.strip()\n        stopWords.append(word)\n        line = fp.readline()\n    fp.close()\n    return stopWords",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Process individual vectors and return a vector "
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def wordProcess(tweet, stopWords):\n    processedVector = []\n    words = tweet.split()\n    for w in words:\n        #strip punctuation\n        w = w.strip('\\'\"?,.')\n        #check if it consists of only words\n        val = re.search(r\"^[a-zA-Z][a-zA-Z0-9]*[a-zA-Z]+[a-zA-Z0-9]*$\", w)\n        #ignore if it is a stopWord\n        if(w in stopWords or val is None):\n            continue\n        else:\n            processedVector.append(w.lower())\n    return processedVector",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Acquires all the keywords from file"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def getWordList(fileName):\n    fp = open(fileName, 'r')\n    line = fp.readline()\n    wordList = []\n    while line:\n        line = line.strip()\n        wordList.append(line)\n        line = fp.readline()\n    fp.close()\n    return wordList",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Extracts words from tweets"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def extractWord(tweet):\n    tweet_words = set(tweet)\n    words = {}\n    for word in wordList:\n        words['contains(%s)' % word] = (word in tweet_words)\n    return words",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Process the tweets"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "inpTweets = csv.reader(open('data/training.csv', 'rb'), delimiter=',', quotechar='\"')\nstopWords = extractStopWords('data/stopwords.txt')\nwordList = getWordList('data/wordList.txt')\ntweets = []\nfor row in inpTweets:\n    label = row[1]\n    tweet = row[2]\n    cleant = clean(tweet)\n    processedVector = wordProcess(cleant, stopWords)\n    tweets.append((processedVector, label))",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Train and classify"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "training_set = nltk.classify.util.apply_features(extractWord, tweets)\nNBClassifier = nltk.NaiveBayesClassifier.train(training_set)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": "'training_set = nltk.classify.util.apply_features(extractWord, tweets)\\nNBClassifier = nltk.NaiveBayesClassifier.train(training_set)'"
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Cache the classifier"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def SaveClassifier(NBClassifier):\n  fModel = open('BayesModel.pkl',\"wb\")\n  pickle.dump(NBClassifier, fModel,1)\n  fModel.close()\n  #os.system(\"rm BayesModel.pkl.gz\")\n  os.system(\"gzip BayesModel.pkl\")\nSaveClassifier(NBClassifier)\n\ndef LoadClassifier( ):\n  os.system(\"gunzip BayesModel.pkl.gz\")\n  fModel = open('BayesModel.pkl',\"rb\")\n  NBClassifier = pickle.load(fModel)\n  fModel.close()\n  os.system(\"gzip BayesModel.pkl\")\n  return NBClassifier\nclassifier2=LoadClassifier()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Initializations"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "differentWords=[]\nseen=[]\ncorrect=[]\ntwitter=[]\ntestT=csv.reader(open('data/test.csv', 'rb'), delimiter=',', quotechar='\"')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Test and classify"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "for row in testT:\n    testTweet = row[2]\n    correct.append(row[1])\n    cleantTestTweet= clean(testTweet)\n    twitter.append(cleantTestTweet)\n    label = classifier2.classify(extractWord(wordProcess(cleantTestTweet, stopWords)))\n    seen.append(label)\n    #print(\"label = %s\\n\" % (label)) #prints the label(Sports or Politics)\n    ",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Accuracy"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "count=0\nfor i in range(0,499):\n        if(seen[i]==correct[i]):\n           count=count+1;\n        else:\n           differentWords.append(twitter[i]) \nprint((count*100)/(500.0))\n        ",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "94.6\n"
      }
     ],
     "prompt_number": 13
    }
   ],
   "metadata": {}
  }
 ]
}